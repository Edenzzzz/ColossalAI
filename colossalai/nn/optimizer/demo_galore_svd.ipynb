{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD with a padded row demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded master param shape: torch.Size([10])\n",
      "rank 0 padded shape: torch.Size([6])\n",
      "galore projector: tensor([[-0.2985, -0.0810],\n",
      "        [ 0.8539, -0.4677],\n",
      "        [-0.4263, -0.8802]])\n",
      "projector w/o padding:tensor([[-0.2985,  0.8539, -0.4263],\n",
      "        [-0.0810, -0.4677, -0.8802]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9201,  0.2474],\n",
       "         [-0.4949,  0.1362]]),\n",
       " tensor([[-1.3687,  0.5449,  0.3914],\n",
       "         [-2.0443, -0.9566,  1.4912]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "dp_size = 2\n",
    "pad_dim = 0 # add a new row of zeros\n",
    "rank = 2\n",
    "\n",
    "a = torch.randn(3, 3) # working param grads\n",
    "a_copy = a.clone()\n",
    "working_shape = a.shape\n",
    "\n",
    "def shard(a, rank):\n",
    "    a_local = a.chunk(dp_size)[rank]\n",
    "    # Galore padding for SVD\n",
    "    # make it reshapable to a matrix potentially with new all-zero rows\n",
    "    padding = working_shape[pad_dim] - a_local.numel() % working_shape[pad_dim]\n",
    "    a_local = F.pad(a_local, [0, padding]) \n",
    "    return a_local, padding\n",
    "\n",
    "# ZeRO padding \n",
    "a = a.view(-1)\n",
    "zero_padding = a.numel() % dp_size\n",
    "a_zero = F.pad(a, [0,  zero_padding])\n",
    "print(\"padded master param shape:\", a_zero.shape)\n",
    "\n",
    "# Sharding\n",
    "a_rank0, padding = shard(a_zero, 0)\n",
    "a_rank1, _ = shard(a_zero, 1)\n",
    "print(\"rank 0 padded shape:\", a_rank0.shape)\n",
    "\n",
    "# Gather\n",
    "# Galore unpad \n",
    "if padding > 0:\n",
    "    a_rank0 = a_rank0[:-padding]\n",
    "    a_rank1 = a_rank1[:-padding]\n",
    "    \n",
    "a = torch.cat([a_rank0, a_rank1])\n",
    "# ZeRO unpad\n",
    "if zero_padding > 0:\n",
    "    a = a[:-zero_padding]\n",
    "# Must \"re-pad\" to add a zero row/col\n",
    "a = a.reshape((working_shape[pad_dim], -1) if pad_dim == 0 else (-1, working_shape[pad_dim])) \n",
    "U, s, _ = torch.linalg.svd(a)\n",
    "\n",
    "# Galore projector\n",
    "galore_m = U[:rank].T\n",
    "print(f\"galore projector: {galore_m}\")\n",
    "_U, _s, _ = torch.linalg.svd(a_copy)\n",
    "print(f\"projector w/o padding:{_U[:rank]}\")\n",
    "\n",
    "# NOTE: We can't correctly do this...must pad whole-rows or columns \n",
    "a_rank0, padding = shard(a_zero, 0)\n",
    "a_rank0 = a_rank0.reshape((working_shape[pad_dim], -1) if pad_dim == 0 else (-1, working_shape[pad_dim]))\n",
    "galore_m.T @ a_rank0, galore_m.T @ a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.0492, -1.1110],\n",
       "         [-0.3780, -0.0987],\n",
       "         [ 0.6666,  0.0000]]),\n",
       " tensor([-0.3969,  2.2785,  0.8350, -1.4485,  0.0000]),\n",
       " tensor([[ 1.0492, -1.1110, -0.3780],\n",
       "         [-0.0987,  0.6666, -0.3969],\n",
       "         [ 2.2785,  0.8350, -1.4485]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_rank0, a_rank1, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is because the left singular matrix is the eigenvectors of XX^T, which when X is padded with a zero row remain the same.\n",
    "**Reference: https://en.wikipedia.org/wiki/Singular_value_decomposition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-5.7735e-01,  8.1650e-01,  9.4017e-08],\n",
       "         [-5.7735e-01, -4.0825e-01, -7.0711e-01],\n",
       "         [-5.7735e-01, -4.0825e-01,  7.0711e-01]]),\n",
       " tensor([[-0.5774,  0.8165,  0.0000],\n",
       "         [-0.5774, -0.4082, -0.7071],\n",
       "         [-0.5774, -0.4082,  0.7071]]),\n",
       " tensor([[-5.7735e-01+0.j, -4.5907e-04+0.j, -4.5923e-04+0.j],\n",
       "         [-5.7735e-01+0.j,  7.0734e-01+0.j, -7.0688e-01+0.j],\n",
       "         [-5.7735e-01+0.j, -7.0688e-01+0.j,  7.0734e-01+0.j]]),\n",
       " tensor([[ 3.0000e+00,  4.2426e+00, -3.0526e-07],\n",
       "         [ 3.0000e+00,  4.2426e+00,  1.5263e-07],\n",
       "         [ 3.0000e+00,  4.2426e+00,  1.5263e-07]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.cat([torch.ones(3, 3), torch.zeros(3, 1)], dim=-1)\n",
    "U, s, v = torch.linalg.svd(a @ a.T)\n",
    "_, eigvec = torch.linalg.eig(a @ a.T)\n",
    "_U, *_ = torch.linalg.svd(torch.ones(3,3))\n",
    "U, _U, eigvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "import torch\n",
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "            pretrained_model_name_or_path='roberta-large',\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "# del model\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# print(torch.cuda.memory_summary())\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if isinstance(obj, torch.Tensor) or (hasattr(obj, 'data') and isinstance(obj.data, torch.Tensor)):\n",
    "            print(type(obj), obj.shape())\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colossalai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
